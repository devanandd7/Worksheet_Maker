{
    "success": true,
    "message": "PDF uploaded successfully",
    "data": {
        "pdfUrl": "https://res.cloudinary.com/dnpultjwg/raw/upload/v1770221000/worksheet-ai/samples/69834ab1fa0ee54bc1f2cc9e/sample_1770220996369.pdf",
        "publicId": "worksheet-ai/samples/69834ab1fa0ee54bc1f2cc9e/sample_1770220996369.pdf",
        "size": 519648,
        "extractedText": "\n\n \n \n  \n          \n         \nExperiment No. - 6  \n \n   \n      \n Student Name: Devanand Utkarsh            UID: 24MCA20454            \n Branch: MCA                                 Section/Group: 6(B)      \n Semester: II                                   Date of Performance: 1/11/25      \n Subject Name: MACHINE LEARNING LAB              Subject Code: 24CAP-702   \n      \nAim/Overview of the practical:      \nAim:   \nWrite a program based on Artificial neural (using Tensor flow). Also specify the data set \nused with number of input and output variables.  \n  \nProblem – You built a Neural Network model using TensorFlow/Keras to predict diabetes \nbased on patient health data (from diabetes.csv dataset).  \n  \nDataset --  a) diabetes.csv'  \n  \n  \nOBJECTIVE   \n We learn how an artificial neural network can classify flowers based on feature patterns. \n This helps us understand ANN structure, training, and prediction using real-world data.  \n   \nTasks Performed  \n1. Imported required Python libraries.  \n2. Loaded and explored the Diabetes dataset.  \n3. Separated features (X) and target (y).  \n4. Split data into training and testing sets.  \n5. Scaled features using StandardScaler.  \n6. Built ANN model using Keras Sequential API.  \n7. Added Dense layers with ReLU and Sigmoid activations.  \n\n        \n \n8. Compiled the \nmodel using Adam optimizer and binary crossentropy loss.  \n9. Trained the model for 150 epochs.  \n10. Evaluated performance using accuracy and loss.  \n           \n  \n  \n11. Visualized training graphs (Loss & Accuracy).  \n             12.Created and displayed the Confusion Matrix.  \n  \n  \nCode –   \n  \nimport numpy as np from sklearn.datasets import \nload_iris from sklearn.model_selection import \ntrain_test_split from sklearn.preprocessing import \nOneHotEncoder from tensorflow.keras.models \nimport Sequential from tensorflow.keras.layers \nimport Dense import matplotlib.pyplot as plt  \n  \n  \ndf = pd.read_csv('/content/diabetes.csv') \ndisplay(df.head()) display(df.info()) from \nsklearn.model_selection import train_test_split \nfrom sklearn.preprocessing import StandardScaler  \n  \nX = df.drop('Outcome', axis=1) y \n= df['Outcome']  \n  \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \nrandom_state=42)  \n  \nscaler = StandardScaler()  \nX_train_scaled = scaler.fit_transform(X_train) \nX_test_scaled = scaler.transform(X_test) from \ntensorflow.keras.models import Sequential from \ntensorflow.keras.layers import Dense  \n  \n\n        \n \nmodel  =  Sequential() \nmodel.add(Dense(12, input_dim=X_train_scaled.shape[1], activation='relu')) \nmodel.add(Dense(8, activation='relu')) model.add(Dense(1, \nactivation='sigmoid')) model.compile(loss='binary_crossentropy',  \noptimizer='adam', metrics=['accuracy'])  \n  \nmodel.summary() history = model.fit(X_train_scaled, y_train, \nepochs=150, batch_size=10) loss, accuracy = \nmodel.evaluate(X_test_scaled, y_test, verbose=0) print(f\"Test Loss: \n{loss:.4f}\")  \n  \n  \nprint(f\"Test Accuracy: {accuracy:.4f}\") plt.figure(figsize=(12, \n6))  \n  \nplt.subplot(1, 2, 1) \nplt.plot(history.history['loss']) \nplt.title('Training Loss over Epochs') \nplt.xlabel('Epoch') plt.ylabel('Loss')  \n  \nplt.subplot(1, 2, 2) \nplt.plot(history.history['accuracy']) \nplt.title('Training Accuracy over Epochs') \nplt.xlabel('Epoch') plt.ylabel('Accuracy')  \n  \nplt.tight_layout() plt.show()  \n  \nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay  \n  \n# Generate predictions y_pred_proba = \nmodel.predict(X_test_scaled)  \n  \n# Convert probabilities to binary class labels y_pred \n= (y_pred_proba > 0.5).astype(int)  \n  \n# Generate confusion matrix cm = \nconfusion_matrix(y_test, y_pred)  \n  \n\n        \n \n#    Visualize    the \nconfusion matrix disp = \nConfusionMatrixDisplay(confusion_matrix=cm) \ndisp.plot() plt.title('Confusion Matrix') plt.show()  \n  \n  \nOUTPUT -  \n  \n  \n  \n  \n\n        \n \n                \n  \n  \n  \n  \n Learning Outcome:   \nAfter doing this project, you learn to:  \n1. Load and preprocess data using pandas and scikit-learn.  \n2. Scale features using StandardScaler for better neural network performance.  \n3. Build an Artificial Neural Network (ANN) using Keras’ Sequential model.  \n4. Use activation functions like relu and sigmoid appropriately.  \n5. Compile and train the model with binary_crossentropy loss for classification.  \n6. Visualize model performance (loss & accuracy graphs).  \n7. Evaluate results using metrics like accuracy and confusion matrix.  \n  ",
        "pages": 5
    }
}